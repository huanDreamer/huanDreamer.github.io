{"name":"MySQL","slug":"MySQL","count":2,"posts":[{"title":"分布式数据库中间件 MyCat 搞起来！","slug":"分布式数据库中间件MyCat搞起来！","date":"2019-06-28T07:51:14.014Z","updated":"2019-06-28T07:51:14.856Z","comments":true,"pin":null,"path":"api/articles/分布式数据库中间件MyCat搞起来！.json","excerpt":"","keywords":null,"cover":"https://user-gold-cdn.xitu.io/2019/6/28/16b9b999eca3fda2?imageView2/0/w/1280/h/960/ignore-error/1","content":"<blockquote>\n<p>本文转载自 <a href=\"https://juejin.im/post/5d1566caf265da1ba77cb708\" target=\"_blank\" rel=\"noopener\">https://juejin.im/post/5d1566caf265da1ba77cb708</a> </p>\n</blockquote>\n<p>关于 MyCat 的铺垫文章已经写了三篇了：</p>\n<pre><code>1. [MySQL 只能做小项目？松哥要说几句公道话！](https://link.juejin.im?target=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FbcyjBgEqg6Or5zdi4jHaiA)\n1. [北冥有 Data，其名为鲲，鲲之大，一个 MySQL 放不下！](https://link.juejin.im?target=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FqUGANVj2mmoMwUZEV5Zc1w)\n1. [What？Tomcat 竟然也算中间件？](https://link.juejin.im?target=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2F7pj5E2HvmiejBJrW0T86oQ)</code></pre><p>今天终于可以迎接我们的大 Boss 出场了！</p>\n<h1 id=\"MyCat-简介\"><a href=\"#MyCat-简介\" class=\"headerlink\" title=\"MyCat 简介\"></a>MyCat 简介</h1><p>前面文章我们提到，如果数据量比较大的话，我们需要对数据进行分库分表，分完之后，原本存在一个数据库中的数据，现在就存在多个数据库中了，就像下面这样：</p>\n<p><img src=\"https://user-gold-cdn.xitu.io/2019/6/28/16b9b999eca3fda2?imageView2/0/w/1280/h/960/ignore-error/1\" alt></p>\n<p>那么此时 MyCat 所扮演的角色就是分布式数据库中间件！</p>\n<p>MyCat 是一个开源的分布式数据库中间件，它实现了 MySQL 协议，在开发者眼里，他就是一个数据库代理，我们甚至可以使用 MySQL 的客户端工具以及命令行来访问 MyCat 。</p>\n<p>MyCat 现在已经不仅仅只支持 MySQL 了，同时也支持 MSSQL、Oracle、DB2、以及 PostgreSQL等主流数据库。甚至像 MongoDB 这种 NoSQL 也支持。</p>\n<h1 id=\"快速入门\"><a href=\"#快速入门\" class=\"headerlink\" title=\"快速入门\"></a>快速入门</h1><h2 id=\"搭建读写分离\"><a href=\"#搭建读写分离\" class=\"headerlink\" title=\"搭建读写分离\"></a>搭建读写分离</h2><p>要搞 MyCat ，一般要先搭建好 MySQL 的读写分离，MySQL 的读写分离可以参考松哥之前的这篇文章：</p>\n<pre><code>1. [提高性能，MySQL 读写分离环境搭建(二)](https://link.juejin.im?target=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2FSC0OYM6yO_GxQh9DvSsnoQ)</code></pre><h2 id=\"MyCat-安装\"><a href=\"#MyCat-安装\" class=\"headerlink\" title=\"MyCat 安装\"></a>MyCat 安装</h2><p>环境：</p>\n<pre><code>* CentOS7\n* JDK1.8</code></pre><p>MyCat 使用 Java 开发，因此，运行 MyCat ，一定要具备 Java 环境，配置 Java 运行环境这个比较容易，网上资料也很多，我就不详细介绍了。</p>\n<p>Java 环境安装好之后，首先下载 MyCat：</p>\n<div class=\"highlight-wrap\"autocomplete=\"off\" autocorrect=\"off\" autocapitalize=\"off\" spellcheck=\"false\" contenteditable=\"true\"data-rel=\"PLAIN\"><figure class=\"iseeu highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">wget http://dl.mycat.io/1.6.7.1/Mycat-server-1.6.7.1-release-20190213150257-linux.tar.gz</span><br></pre></td></tr></table></figure></div>\n\n<p>下载完成后，对下载文件进行解压。</p>\n<div class=\"highlight-wrap\"autocomplete=\"off\" autocorrect=\"off\" autocapitalize=\"off\" spellcheck=\"false\" contenteditable=\"true\"data-rel=\"PLAIN\"><figure class=\"iseeu highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">tar -zxvf Mycat-server-1.6.7.1-release-20190213150257-linux.tar.gz</span><br></pre></td></tr></table></figure></div>\n\n<p>解压成功后，会出现一个 <code>mycat</code> 目录，进入到 <code>mycat/conf</code> 目录，对 <code>mycat</code> 进行配置：</p>\n<p>首先来配置 <code>schema.xml</code> 文件：</p>\n<p><img src=\"https://user-gold-cdn.xitu.io/2019/6/28/16b9b999ec783a97?imageView2/0/w/1280/h/960/ignore-error/1\" alt></p>\n<pre><code>1. 首先在 `schema` 中指定逻辑库的名字，逻辑库是指 `MyCat` 中的库，这个库不存储数据，数据存储在 `MySQL` 中的物理库中。\n1. 逻辑库中配置逻辑表，配置逻辑表时，需要指定 `dataNode` 节点， `dataNode` 就是指数据库存储的位置\n1. 配置 `dataNode` ，`dataNode` 指定 `dataHost` 和物理库的名字。\n1. `dataHost` 则配置 `MySQL` 的主机和从机的位置，登录密码等。主机和从机都可以配置多个。</code></pre><p>配置完 schema.xml 后 ，接下来配置 server.xml。</p>\n<p>server.xml 中主要配置 MyCat 的登录用户名和密码，以及需要操作的逻辑库。</p>\n<p><img src=\"https://user-gold-cdn.xitu.io/2019/6/28/16b9b99a1a7fec73?imageView2/0/w/1280/h/960/ignore-error/1\" alt></p>\n<p>配置完成后，接下来就可以启动 MyCat 了 。</p>\n<p>执行 MyCat 解压目录下的 bin 目录下的 mycat 命令，可以启动 MyCat</p>\n<div class=\"highlight-wrap\"autocomplete=\"off\" autocorrect=\"off\" autocapitalize=\"off\" spellcheck=\"false\" contenteditable=\"true\"data-rel=\"PLAIN\"><figure class=\"iseeu highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">./bin/mycat start</span><br></pre></td></tr></table></figure></div>\n\n<p>如果启动后，提示无法创建 <code>mycat.pid</code> 文件，就自己手动创建一个 <code>mycat.pid</code> 文件。启动成功之后，就可以在本地连接 <code>MyCat</code> 了，连接方式和 <code>MySQL</code> 一样，唯一的区别在于端口号不同。</p>\n<p>在连接 <code>MyCat</code> 之前，先在 <code>MySQL</code> 物理库中创建 <code>db1</code>、<code>db2</code> 以及 <code>db3</code> 三个数据库。</p>\n<p>使用 <code>SQLyog</code> 连接：</p>\n<p><img src=\"https://user-gold-cdn.xitu.io/2019/6/28/16b9b999ecbdcb90?imageView2/0/w/1280/h/960/ignore-error/1\" alt></p>\n<p>也可以在 <code>cmd</code> 命令行登录 <code>MyCat</code> ：</p>\n<p><img src=\"https://user-gold-cdn.xitu.io/2019/6/28/16b9b999f41ebb17?imageView2/0/w/1280/h/960/ignore-error/1\" alt></p>\n<p>登录成功后 ，在 <code>MyCat</code> 的窗口中，执行如下命令，创建表：</p>\n<div class=\"highlight-wrap\"autocomplete=\"off\" autocorrect=\"off\" autocapitalize=\"off\" spellcheck=\"false\" contenteditable=\"true\"data-rel=\"PLAIN\"><figure class=\"iseeu highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">create table t_user (id integer primary key,username varchar(255))</span><br></pre></td></tr></table></figure></div>\n\n<p>执行成功后，我们会发现物理库中出现了相应的表。 接下来，手动往各个物理库的物理表中存储一条数据，然后在 MyCat 窗口中查询：</p>\n<p><img src=\"https://user-gold-cdn.xitu.io/2019/6/28/16b9b999eccf3c2f?imageView2/0/w/1280/h/960/ignore-error/1\" alt></p>\n<p>这样就可以查询到 三个库中的三个表中的数据。</p>\n<h1 id=\"问题分析\"><a href=\"#问题分析\" class=\"headerlink\" title=\"问题分析\"></a>问题分析</h1><p>整个过程不难，但是有的小伙伴在第一次配置的过程中还是容易出错，因此我这里还是来说两句，出错了要如何定位。</p>\n<p>一般来说，配置 MyCat 出错，问题可能发生在两个阶段。第一个阶段就是客户端连接 MyCat 出错，第二个阶段就是 MyCat 连接 MySQL 出错。</p>\n<p>无论你是使用 SQLyog 还是 Navicat ，我们在连接数据库的过程中，都可以先测试连接，很多人卡在这一步。</p>\n<p>如果在测试连接的时候就连接不通，说明是 MyCat 的问题，这个时候检查步骤如下：</p>\n<pre><code>1. 首先当然是查看日志信息，看能不能找出端倪\n1. 通过 jps 命令查看 mycat 是否成功启动\n1. 检查 server.xml 中配置是否正确，用户名密码是否输入正确</code></pre><p>这是第一种可能的问题，第二种问题就是测试连接没问题，但是测试完后，却连接不上。反映到 Navicat 上，就是测试连接没问题，测完之后，点击连接名要打开连接时，Navicat 就崩了，出现这个问题一般是 MyCat 在连接 MySQL 出问题了，这个时候就要去检查 schema.xml 文件中关于 MySQL 主机和从机的配置是否正确，数据库地址是否正确，用户名密码是否正确。</p>\n<h1 id=\"结语\"><a href=\"#结语\" class=\"headerlink\" title=\"结语\"></a>结语</h1><p>好了，本文主要简单介绍了下 MyCat 的安装问题，下篇文章我们来看 MyCat 中的分片规则问题。</p>\n<p>参考资料：</p>\n<pre><code>1. [MyCat 官方文档](https://link.juejin.im?target=http%3A%2F%2Fwww.mycat.io%2F)</code></pre><p>关注公众号【江南一点雨】，专注于 Spring Boot+微服务以及前后端分离等全栈技术，定期视频教程分享，关注后回复 Java ，领取松哥为你精心准备的 Java 干货！<br><img src=\"https://user-gold-cdn.xitu.io/2019/6/28/16b9b99ae9446d11?imageView2/0/w/1280/h/960/ignore-error/1\" alt></p>\n","text":"本文转载自 https://juejin.im/post/5d1566caf265da1ba77cb708 关于 MyCat 的铺垫文章已经写了三篇了：1. [MySQL 只能做小项目？松哥要说几句公道话！](https://link.juejin.im?target=https","link":"","raw":null,"photos":[],"categories":[],"tags":[{"name":"MySQL","slug":"MySQL","count":2,"path":"api/tags/MySQL.json"}]},{"title":"用大白话告诉你小白都能看懂的Hadoop架构原理","slug":"用大白话告诉你小白都能看懂的Hadoop架构原理","date":"2019-05-21T01:57:19.019Z","updated":"2019-05-30T00:52:25.433Z","comments":true,"pin":null,"path":"api/articles/用大白话告诉你小白都能看懂的Hadoop架构原理.json","excerpt":"","keywords":null,"cover":"https://user-gold-cdn.xitu.io/2018/11/13/1670dbfd11e62805?imageView2/0/w/1280/h/960/ignore-error/1","content":"<blockquote>\n<p>本文转载自 <a href=\"https://juejin.im/post/5beaf02ce51d457e90196069\" target=\"_blank\" rel=\"noopener\">https://juejin.im/post/5beaf02ce51d457e90196069</a> </p>\n</blockquote>\n<p><strong>欢迎关注个人微信号：石杉的架构笔记（id：shishan100）</strong></p>\n<p><strong>周一至周五早8点半！精品技术文章准时送上！</strong></p>\n<hr>\n<p><strong>往期文章</strong></p>\n<p>1、<a href=\"https://juejin.im/post/5be13b83f265da6116393fc7\" target=\"_blank\" rel=\"noopener\">拜托！面试请不要再问我Spring Cloud底层原理</a></p>\n<p>2、<a href=\"https://juejin.im/post/5be3f8dcf265da613a5382ca\" target=\"_blank\" rel=\"noopener\">【双11狂欢的背后】微服务注册中心如何承载大型系统的千万级访问？</a></p>\n<p>3、<a href=\"https://juejin.im/post/5be83e166fb9a049a7115580\" target=\"_blank\" rel=\"noopener\">【性能优化之道】每秒上万并发下的Spring Cloud参数优化实战</a></p>\n<p>4、<a href=\"https://juejin.im/post/5be99a68e51d4511a8090440\" target=\"_blank\" rel=\"noopener\">微服务架构如何保障双11狂欢下的99.99%高可用</a></p>\n<hr>\n<h3 id=\"目录\"><a href=\"#目录\" class=\"headerlink\" title=\"目录\"></a>目录</h3><p>一、前奏</p>\n<p>二、HDFS的NameNode架构原理</p>\n<h1 id=\"一、前奏\"><a href=\"#一、前奏\" class=\"headerlink\" title=\"一、前奏\"></a>一、前奏</h1><p>Hadoop是目前大数据领域最主流的一套技术体系，包含了多种技术。</p>\n<p>包括HDFS（分布式文件系统），YARN（分布式资源调度系统），MapReduce（分布式计算系统），等等。</p>\n<p>有些朋友可能听说过Hadoop，但是却不太清楚他到底是个什么东西，这篇文章就用大白话给各位阐述一下。</p>\n<p>假如你现在公司里的数据都是放在MySQL里的，那么就全部放在一台数据库服务器上，我们就假设这台服务器的磁盘空间有2T吧，<strong>大家先看下面这张图。</strong></p>\n<p><img src=\"https://user-gold-cdn.xitu.io/2018/11/13/1670dbfd11e62805?imageView2/0/w/1280/h/960/ignore-error/1\" alt><br><a href></a></p>\n<p><a href></a></p>\n<p>现在问题来了，你不停的往这台服务器的MySQL里放数据，结果数据量越来越大了，超过了2T的大小了，现在咋办？</p>\n<p>你说，我可以搞多台MySQL数据库服务器，分库分表啊！每台服务器放一部分数据不就得了。<strong>如上图所示！</strong></p>\n<p>好，没问题，那咱们搞3台数据库服务器，3个MySQL实例，然后每台服务器都可以2T的数据。</p>\n<p>现在我问你一个问题，<strong>所谓的大数据是在干什么？</strong></p>\n<p>我们来说一下大数据最初级的一个使用场景。假设你有一个电商网站，现在要把这个电商网站里所有的用户在页面和APP上的点击、购买、浏览的行为日志都存放起来分析。</p>\n<p>你现在把这些数据全都放在了3台MySQL服务器，数据量很大，但还是勉强可以放的下。</p>\n<p>某天早上，你的boss来了。要看一张报表，比如要看每天网站的X指标、Y指标、Z指标，等等，二三十个数据指标。</p>\n<p>好了，兄弟，现在你尝试去从那些点击、购买、浏览的日志里，通过写一个SQL来分析出那二三十个指标试试看？</p>\n<p>我跟你打赌，你绝对会写出来一个几百行起步，甚至上千行的超级复杂大SQL。这个SQL，你觉得他能运行在分库分表后的3台MySQL服务器上么？</p>\n<p>如果你觉得可以的话，那你一定是不太了解MySQL分库分表后有多坑，几百行的大SQL跨库join，各种复杂的计算，根本不现实。</p>\n<p>所以说，大数据的存储和计算压根儿不是靠MySQL来搞的，因此，Hadoop、Spark等大数据技术体系才应运而生。</p>\n<p>本质上，Hadoop、Spark等大数据技术，其实就是一系列的分布式系统。</p>\n<p>比如hadoop中的HDFS，就是大数据技术体系中的核心基石，<strong>负责分布式存储数据，这是啥意思？别急，继续往下看。</strong></p>\n<p>HDFS全称是Hadoop Distributed File System，是Hadoop的分布式文件系统。</p>\n<p>它由很多机器组成，每台机器上运行一个DataNode进程，负责管理一部分数据。</p>\n<p>然后有一台机器上运行了NameNode进程，NameNode大致可以认为是负责管理整个HDFS集群的这么一个进程，他里面存储了HDFS集群的所有元数据。</p>\n<p>然后有很多台机器，每台机器存储一部分数据！好，HDFS现在可以很好的存储和管理大量的数据了。</p>\n<p>这时候你肯定会有疑问：MySQL服务器也不是这样的吗？你要是这样想，那就大错特错了。</p>\n<p>这个事情不是你想的那么简单的，HDFS天然就是分布式的技术，所以你上传大量数据，存储数据，管理数据，天然就可以用HDFS来做。</p>\n<p>如果你硬要基于MySQL分库分表这个事儿，会痛苦很多倍，因为MySQL并不是设计为分布式系统架构的，他在分布式数据存储这块缺乏很多数据保障的机制。</p>\n<p>好，你现在用HDFS分布式存储了数据，接着不就是要分布式来计算这些数据了吗？</p>\n<p>对于分布式计算：</p>\n<pre><code>* 很多公司用Hive写几百行的大SQL（底层基于MapReduce）\n* 也有很多公司开始慢慢的用Spark写几百行的大SQL（底层是Spark Core引擎）。</code></pre><p>总之就是写一个大SQL，人家会拆分为很多的计算任务，放到各个机器上去，每个计算任务就负责计算一小部分数据，这就是所谓的分布式计算。</p>\n<p>这个，绝对比你针对分库分表的MySQL来跑几百行大SQL要靠谱的多。</p>\n<p>对于上述所说，老规矩，同样给大家来一张图，大伙儿跟着图来仔细捋一下整个过程。</p>\n<p><img src=\"https://user-gold-cdn.xitu.io/2018/11/13/1670dc005dc982dc?imageView2/0/w/1280/h/960/ignore-error/1\" alt><br><a href></a></p>\n<p><a href></a></p>\n<h1 id=\"二、HDFS的NameNode架构原理\"><a href=\"#二、HDFS的NameNode架构原理\" class=\"headerlink\" title=\"二、HDFS的NameNode架构原理\"></a>二、HDFS的NameNode架构原理</h1><p>好了，前奏铺垫完之后，进入正题。本文其实主要就是讨论一下HDFS集群中的NameNode的核心架构原理。</p>\n<p>NameNode有一个很核心的功能：<strong>管理整个HDFS集群的元数据</strong>，比如说文件目录树、权限的设置、副本数的设置，等等。</p>\n<p>下面就用最典型的文件目录树的维护，来给大家举例说明，<strong>我们看看下面的图。</strong>现在有一个客户端系统要上传一个1TB的大文件到HDFS集群里。</p>\n<p><img src=\"https://user-gold-cdn.xitu.io/2018/11/13/1670dc022eeddf7f?imageView2/0/w/1280/h/960/ignore-error/1\" alt><br><a href></a></p>\n<p><a href></a></p>\n<p>此时他会先跟NameNode通信，说：大哥，我想创建一个新的文件，他的名字叫“/usr/hive/warehouse/access_20180101.log”，大小是1TB，你看行不？</p>\n<p>然后NameNode就会在自己内存的文件目录树里，在指定的目录下搞一个新的文件对象，名字就是“access_20180101.log”。</p>\n<p>这个文件目录树不就是HDFS非常核心的一块元数据，维护了HDFS这个分布式文件系统中，有哪些目录，有哪些文件，对不对？</p>\n<p>但是有个问题，这个文件目录树是在NameNode的内存里的啊！</p>\n<p>这可坑爹了，你把重要的元数据都放在内存里，<strong>万一NameNode不小心宕机了可咋整？元数据不就全部丢失了？</strong></p>\n<p>可你要是每次都频繁的修改磁盘文件里的元数据，性能肯定是极低的啊！毕竟这是大量的磁盘随机读写！</p>\n<p>没关系，<strong>我们来看看HDFS优雅的解决方案。</strong></p>\n<p>每次内存里改完了，写一条edits log，元数据修改的操作日志到磁盘文件里，不修改磁盘文件内容，就是顺序追加，这个性能就高多了。</p>\n<p>每次NameNode重启的时候，把edits log里的操作日志读到内存里回放一下，不就可以恢复元数据了？</p>\n<p><strong>大家顺着上面的文字，把整个过程，用下面这张图跟着走一遍。</strong></p>\n<hr>\n<p><img src=\"https://user-gold-cdn.xitu.io/2018/11/13/1670dc03f2942281?imageView2/0/w/1280/h/960/ignore-error/1\" alt><br><a href></a></p>\n<p><a href></a></p>\n<p>但是问题又来了，那edits log如果越来越大的话，岂不是每次重启都会很慢？因为要读取大量的edits log回放恢复元数据！</p>\n<p>所以HDFS说，我可以这样子啊，我引入一个新的磁盘文件叫做<strong>fsimage</strong>，然后呢，再引入一个<strong>JournalNodes</strong>集群，以及一个<strong>Standby NameNode</strong>（备节点）。</p>\n<p>每次Active NameNode（主节点）修改一次元数据都会生成一条edits log，<strong>除了写入本地磁盘文件，还会写入JournalNodes集群。</strong></p>\n<p>然后Standby NameNode就可以从JournalNodes集群拉取edits log，应用到自己内存的文件目录树里，跟Active NameNode保持一致。</p>\n<p>然后每隔一段时间，Standby NameNode都把自己内存里的文件目录树写一份到磁盘上的fsimage，这可不是日志，这是完整的一份元数据。<strong>这个操作就是所谓的checkpoint检查点操作。</strong></p>\n<p>然后把这个fsimage上传到到Active NameNode，接着清空掉Active NameNode的旧的edits log文件，这里可能都有100万行修改日志了！</p>\n<p>然后Active NameNode继续接收修改元数据的请求，再写入edits log，写了一小会儿，这里可能就几十行修改日志而已！</p>\n<p>如果说此时，Active NameNode重启了，bingo！没关系，只要把Standby NameNode传过来的fsimage直接读到内存里，<strong>这个fsimage直接就是元数据</strong>，不需要做任何额外操作，纯读取，效率很高！</p>\n<p>然后把新的edits log里少量的几十行的修改日志回放到内存里就ok了！</p>\n<p>这个过程的启动速度就快的多了！因为不需要回放大量上百万行的edits log来恢复元数据了！如下图所示。</p>\n<p><img src=\"https://user-gold-cdn.xitu.io/2018/11/13/1670dc062e2fa9e8?imageView2/0/w/1280/h/960/ignore-error/1\" alt><br><a href></a></p>\n<p><a href></a></p>\n<p>此外，<strong>大家看看上面这张图</strong>，现在咱们有俩NameNode。</p>\n<pre><code>* 一个是主节点对外提供服务接收请求\n* 另外一个纯就是接收和同步主节点的edits log以及执行定期checkpoint的备节点。</code></pre><p>大家有没有发现！他们俩内存里的元数据几乎是一模一样的啊！</p>\n<p>所以呢，如果Active NameNode挂了，是不是可以立马切换成Standby NameNode对外提供服务？</p>\n<p><strong>这不就是所谓的NameNode主备高可用故障转移机制么！</strong></p>\n<p>接下来大家再想想，HDFS客户端在NameNode内存里的文件目录树，新加了一个文件。</p>\n<p>但是这个时候，人家要把数据上传到多台DataNode机器上去啊，<strong>这可是一个1TB的大文件！咋传呢？</strong></p>\n<p>很简单，<strong>把1TB的大文件拆成N个block</strong>，每个block是128MB。1TB = 1024GB = 1048576MB，一个block是128MB，那么就是对应着8192个block。</p>\n<p>这些block会分布在不同的机器上管理着，比如说一共有100台机器组成的集群，那么每台机器上放80个左右的block就ok了。</p>\n<p>但是问题又来了，那如果这个时候1台机器宕机了，不就导致80个block丢失了？</p>\n<p>也就是说上传上去的1TB的大文件，会丢失一小部分数据啊。没关系！HDFS都考虑好了！</p>\n<p>它会<strong>默认给每个block搞3个副本</strong>，一模一样的副本，分放在不同的机器上，如果一台机器宕机了，同一个block还有另外两个副本在其他机器上呢！</p>\n<p><strong>大伙儿看看下面这张图</strong>。每个block都在不同的机器上有3个副本，任何一台机器宕机都没事！还可以从其他的机器上拿到那个block。</p>\n<p>这下子，你往HDFS上传一个1TB的大文件，可以高枕无忧了吧！</p>\n<p><img src=\"https://user-gold-cdn.xitu.io/2018/11/13/1670dc07b1a880a6?imageView2/0/w/1280/h/960/ignore-error/1\" alt><br><a href></a></p>\n<p><a href></a></p>\n<p>OK，上面就是大白话加上一系列手绘图，给大家先聊聊小白都能听懂的Hadoop的基本架构原理</p>\n<p>接下来会给大家聊聊HDFS，这个作为世界上最优秀的分布式存储系统，承载高并发请求、高性能文件上传的一些核心机制以及原理。</p>\n<p><strong>《大规模集群下Hadoop如何承载每秒上千次的高并发访问》，</strong>敬请期待</p>\n<p><strong>《【冰山下的秘密】Hadoop如何将TB级大文件的上传性能提升上百倍？》</strong>，敬请期待</p>\n<p><strong>如有收获，请帮忙转发，您的鼓励是作者最大的动力，谢谢！</strong></p>\n<p><strong>一大波微服务、分布式、高并发、高可用的**</strong>原创系列<strong>**文章正在路上,</strong></p>\n<hr>\n<p><strong>**欢迎扫描下方二维码</strong>，持续关注：**\n<img src=\"https://user-gold-cdn.xitu.io/2018/11/12/167088310d1d57b1?imageView2/0/w/1280/h/960/ignore-error/1\" alt></p>\n<p><strong>石杉的架构笔记（id:shishan100）</strong></p>\n<p><strong>十余年BAT架构经验倾囊相授</strong></p>\n","text":"本文转载自 https://juejin.im/post/5beaf02ce51d457e90196069 欢迎关注个人微信号：石杉的架构笔记（id：shishan100）周一至周五早8点半！精品技术文章准时送上！往期文章1、拜托！面试请不要再问我Spring Cloud底层原理","link":"","raw":null,"photos":[],"categories":[],"tags":[{"name":"MySQL","slug":"MySQL","count":2,"path":"api/tags/MySQL.json"},{"name":"架构","slug":"架构","count":4,"path":"api/tags/架构.json"},{"name":"HDFS","slug":"HDFS","count":1,"path":"api/tags/HDFS.json"},{"name":"Hadoop","slug":"Hadoop","count":1,"path":"api/tags/Hadoop.json"}]}]}