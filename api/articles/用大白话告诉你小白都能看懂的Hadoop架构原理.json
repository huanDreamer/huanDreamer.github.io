{"title":"用大白话告诉你小白都能看懂的Hadoop架构原理","slug":"用大白话告诉你小白都能看懂的Hadoop架构原理","date":"2019-05-21T01:57:19.019Z","updated":"2019-05-30T00:52:25.433Z","comments":true,"path":"api/articles/用大白话告诉你小白都能看懂的Hadoop架构原理.json","photos":[],"link":"","excerpt":"","covers":["https://user-gold-cdn.xitu.io/2018/11/13/1670dbfd11e62805?imageView2/0/w/1280/h/960/ignore-error/1","https://user-gold-cdn.xitu.io/2018/11/13/1670dc005dc982dc?imageView2/0/w/1280/h/960/ignore-error/1","https://user-gold-cdn.xitu.io/2018/11/13/1670dc022eeddf7f?imageView2/0/w/1280/h/960/ignore-error/1","https://user-gold-cdn.xitu.io/2018/11/13/1670dc03f2942281?imageView2/0/w/1280/h/960/ignore-error/1","https://user-gold-cdn.xitu.io/2018/11/13/1670dc062e2fa9e8?imageView2/0/w/1280/h/960/ignore-error/1","https://user-gold-cdn.xitu.io/2018/11/13/1670dc07b1a880a6?imageView2/0/w/1280/h/960/ignore-error/1","https://user-gold-cdn.xitu.io/2018/11/12/167088310d1d57b1?imageView2/0/w/1280/h/960/ignore-error/1"],"content":"<blockquote>\n<p>本文转载自 <a href=\"https://juejin.im/post/5beaf02ce51d457e90196069\" target=\"_blank\" rel=\"noopener\">https://juejin.im/post/5beaf02ce51d457e90196069</a> </p>\n</blockquote>\n<p><strong>欢迎关注个人微信号：石杉的架构笔记（id：shishan100）</strong></p>\n<p><strong>周一至周五早8点半！精品技术文章准时送上！</strong></p>\n<hr>\n<p><strong>往期文章</strong></p>\n<p>1、<a href=\"https://juejin.im/post/5be13b83f265da6116393fc7\" target=\"_blank\" rel=\"noopener\">拜托！面试请不要再问我Spring Cloud底层原理</a></p>\n<p>2、<a href=\"https://juejin.im/post/5be3f8dcf265da613a5382ca\" target=\"_blank\" rel=\"noopener\">【双11狂欢的背后】微服务注册中心如何承载大型系统的千万级访问？</a></p>\n<p>3、<a href=\"https://juejin.im/post/5be83e166fb9a049a7115580\" target=\"_blank\" rel=\"noopener\">【性能优化之道】每秒上万并发下的Spring Cloud参数优化实战</a></p>\n<p>4、<a href=\"https://juejin.im/post/5be99a68e51d4511a8090440\" target=\"_blank\" rel=\"noopener\">微服务架构如何保障双11狂欢下的99.99%高可用</a></p>\n<hr>\n<h3 id=\"目录\"><a href=\"#目录\" class=\"headerlink\" title=\"目录\"></a>目录</h3><p>一、前奏</p>\n<p>二、HDFS的NameNode架构原理</p>\n<h1 id=\"一、前奏\"><a href=\"#一、前奏\" class=\"headerlink\" title=\"一、前奏\"></a>一、前奏</h1><p>Hadoop是目前大数据领域最主流的一套技术体系，包含了多种技术。</p>\n<p>包括HDFS（分布式文件系统），YARN（分布式资源调度系统），MapReduce（分布式计算系统），等等。</p>\n<p>有些朋友可能听说过Hadoop，但是却不太清楚他到底是个什么东西，这篇文章就用大白话给各位阐述一下。</p>\n<p>假如你现在公司里的数据都是放在MySQL里的，那么就全部放在一台数据库服务器上，我们就假设这台服务器的磁盘空间有2T吧，<strong>大家先看下面这张图。</strong></p>\n<p><img src=\"https://user-gold-cdn.xitu.io/2018/11/13/1670dbfd11e62805?imageView2/0/w/1280/h/960/ignore-error/1\" alt><br><a href></a></p>\n<p><a href></a></p>\n<p>现在问题来了，你不停的往这台服务器的MySQL里放数据，结果数据量越来越大了，超过了2T的大小了，现在咋办？</p>\n<p>你说，我可以搞多台MySQL数据库服务器，分库分表啊！每台服务器放一部分数据不就得了。<strong>如上图所示！</strong></p>\n<p>好，没问题，那咱们搞3台数据库服务器，3个MySQL实例，然后每台服务器都可以2T的数据。</p>\n<p>现在我问你一个问题，<strong>所谓的大数据是在干什么？</strong></p>\n<p>我们来说一下大数据最初级的一个使用场景。假设你有一个电商网站，现在要把这个电商网站里所有的用户在页面和APP上的点击、购买、浏览的行为日志都存放起来分析。</p>\n<p>你现在把这些数据全都放在了3台MySQL服务器，数据量很大，但还是勉强可以放的下。</p>\n<p>某天早上，你的boss来了。要看一张报表，比如要看每天网站的X指标、Y指标、Z指标，等等，二三十个数据指标。</p>\n<p>好了，兄弟，现在你尝试去从那些点击、购买、浏览的日志里，通过写一个SQL来分析出那二三十个指标试试看？</p>\n<p>我跟你打赌，你绝对会写出来一个几百行起步，甚至上千行的超级复杂大SQL。这个SQL，你觉得他能运行在分库分表后的3台MySQL服务器上么？</p>\n<p>如果你觉得可以的话，那你一定是不太了解MySQL分库分表后有多坑，几百行的大SQL跨库join，各种复杂的计算，根本不现实。</p>\n<p>所以说，大数据的存储和计算压根儿不是靠MySQL来搞的，因此，Hadoop、Spark等大数据技术体系才应运而生。</p>\n<p>本质上，Hadoop、Spark等大数据技术，其实就是一系列的分布式系统。</p>\n<p>比如hadoop中的HDFS，就是大数据技术体系中的核心基石，<strong>负责分布式存储数据，这是啥意思？别急，继续往下看。</strong></p>\n<p>HDFS全称是Hadoop Distributed File System，是Hadoop的分布式文件系统。</p>\n<p>它由很多机器组成，每台机器上运行一个DataNode进程，负责管理一部分数据。</p>\n<p>然后有一台机器上运行了NameNode进程，NameNode大致可以认为是负责管理整个HDFS集群的这么一个进程，他里面存储了HDFS集群的所有元数据。</p>\n<p>然后有很多台机器，每台机器存储一部分数据！好，HDFS现在可以很好的存储和管理大量的数据了。</p>\n<p>这时候你肯定会有疑问：MySQL服务器也不是这样的吗？你要是这样想，那就大错特错了。</p>\n<p>这个事情不是你想的那么简单的，HDFS天然就是分布式的技术，所以你上传大量数据，存储数据，管理数据，天然就可以用HDFS来做。</p>\n<p>如果你硬要基于MySQL分库分表这个事儿，会痛苦很多倍，因为MySQL并不是设计为分布式系统架构的，他在分布式数据存储这块缺乏很多数据保障的机制。</p>\n<p>好，你现在用HDFS分布式存储了数据，接着不就是要分布式来计算这些数据了吗？</p>\n<p>对于分布式计算：</p>\n<pre><code>* 很多公司用Hive写几百行的大SQL（底层基于MapReduce）\n* 也有很多公司开始慢慢的用Spark写几百行的大SQL（底层是Spark Core引擎）。</code></pre><p>总之就是写一个大SQL，人家会拆分为很多的计算任务，放到各个机器上去，每个计算任务就负责计算一小部分数据，这就是所谓的分布式计算。</p>\n<p>这个，绝对比你针对分库分表的MySQL来跑几百行大SQL要靠谱的多。</p>\n<p>对于上述所说，老规矩，同样给大家来一张图，大伙儿跟着图来仔细捋一下整个过程。</p>\n<p><img src=\"https://user-gold-cdn.xitu.io/2018/11/13/1670dc005dc982dc?imageView2/0/w/1280/h/960/ignore-error/1\" alt><br><a href></a></p>\n<p><a href></a></p>\n<h1 id=\"二、HDFS的NameNode架构原理\"><a href=\"#二、HDFS的NameNode架构原理\" class=\"headerlink\" title=\"二、HDFS的NameNode架构原理\"></a>二、HDFS的NameNode架构原理</h1><p>好了，前奏铺垫完之后，进入正题。本文其实主要就是讨论一下HDFS集群中的NameNode的核心架构原理。</p>\n<p>NameNode有一个很核心的功能：<strong>管理整个HDFS集群的元数据</strong>，比如说文件目录树、权限的设置、副本数的设置，等等。</p>\n<p>下面就用最典型的文件目录树的维护，来给大家举例说明，<strong>我们看看下面的图。</strong>现在有一个客户端系统要上传一个1TB的大文件到HDFS集群里。</p>\n<p><img src=\"https://user-gold-cdn.xitu.io/2018/11/13/1670dc022eeddf7f?imageView2/0/w/1280/h/960/ignore-error/1\" alt><br><a href></a></p>\n<p><a href></a></p>\n<p>此时他会先跟NameNode通信，说：大哥，我想创建一个新的文件，他的名字叫“/usr/hive/warehouse/access_20180101.log”，大小是1TB，你看行不？</p>\n<p>然后NameNode就会在自己内存的文件目录树里，在指定的目录下搞一个新的文件对象，名字就是“access_20180101.log”。</p>\n<p>这个文件目录树不就是HDFS非常核心的一块元数据，维护了HDFS这个分布式文件系统中，有哪些目录，有哪些文件，对不对？</p>\n<p>但是有个问题，这个文件目录树是在NameNode的内存里的啊！</p>\n<p>这可坑爹了，你把重要的元数据都放在内存里，<strong>万一NameNode不小心宕机了可咋整？元数据不就全部丢失了？</strong></p>\n<p>可你要是每次都频繁的修改磁盘文件里的元数据，性能肯定是极低的啊！毕竟这是大量的磁盘随机读写！</p>\n<p>没关系，<strong>我们来看看HDFS优雅的解决方案。</strong></p>\n<p>每次内存里改完了，写一条edits log，元数据修改的操作日志到磁盘文件里，不修改磁盘文件内容，就是顺序追加，这个性能就高多了。</p>\n<p>每次NameNode重启的时候，把edits log里的操作日志读到内存里回放一下，不就可以恢复元数据了？</p>\n<p><strong>大家顺着上面的文字，把整个过程，用下面这张图跟着走一遍。</strong></p>\n<hr>\n<p><img src=\"https://user-gold-cdn.xitu.io/2018/11/13/1670dc03f2942281?imageView2/0/w/1280/h/960/ignore-error/1\" alt><br><a href></a></p>\n<p><a href></a></p>\n<p>但是问题又来了，那edits log如果越来越大的话，岂不是每次重启都会很慢？因为要读取大量的edits log回放恢复元数据！</p>\n<p>所以HDFS说，我可以这样子啊，我引入一个新的磁盘文件叫做<strong>fsimage</strong>，然后呢，再引入一个<strong>JournalNodes</strong>集群，以及一个<strong>Standby NameNode</strong>（备节点）。</p>\n<p>每次Active NameNode（主节点）修改一次元数据都会生成一条edits log，<strong>除了写入本地磁盘文件，还会写入JournalNodes集群。</strong></p>\n<p>然后Standby NameNode就可以从JournalNodes集群拉取edits log，应用到自己内存的文件目录树里，跟Active NameNode保持一致。</p>\n<p>然后每隔一段时间，Standby NameNode都把自己内存里的文件目录树写一份到磁盘上的fsimage，这可不是日志，这是完整的一份元数据。<strong>这个操作就是所谓的checkpoint检查点操作。</strong></p>\n<p>然后把这个fsimage上传到到Active NameNode，接着清空掉Active NameNode的旧的edits log文件，这里可能都有100万行修改日志了！</p>\n<p>然后Active NameNode继续接收修改元数据的请求，再写入edits log，写了一小会儿，这里可能就几十行修改日志而已！</p>\n<p>如果说此时，Active NameNode重启了，bingo！没关系，只要把Standby NameNode传过来的fsimage直接读到内存里，<strong>这个fsimage直接就是元数据</strong>，不需要做任何额外操作，纯读取，效率很高！</p>\n<p>然后把新的edits log里少量的几十行的修改日志回放到内存里就ok了！</p>\n<p>这个过程的启动速度就快的多了！因为不需要回放大量上百万行的edits log来恢复元数据了！如下图所示。</p>\n<p><img src=\"https://user-gold-cdn.xitu.io/2018/11/13/1670dc062e2fa9e8?imageView2/0/w/1280/h/960/ignore-error/1\" alt><br><a href></a></p>\n<p><a href></a></p>\n<p>此外，<strong>大家看看上面这张图</strong>，现在咱们有俩NameNode。</p>\n<pre><code>* 一个是主节点对外提供服务接收请求\n* 另外一个纯就是接收和同步主节点的edits log以及执行定期checkpoint的备节点。</code></pre><p>大家有没有发现！他们俩内存里的元数据几乎是一模一样的啊！</p>\n<p>所以呢，如果Active NameNode挂了，是不是可以立马切换成Standby NameNode对外提供服务？</p>\n<p><strong>这不就是所谓的NameNode主备高可用故障转移机制么！</strong></p>\n<p>接下来大家再想想，HDFS客户端在NameNode内存里的文件目录树，新加了一个文件。</p>\n<p>但是这个时候，人家要把数据上传到多台DataNode机器上去啊，<strong>这可是一个1TB的大文件！咋传呢？</strong></p>\n<p>很简单，<strong>把1TB的大文件拆成N个block</strong>，每个block是128MB。1TB = 1024GB = 1048576MB，一个block是128MB，那么就是对应着8192个block。</p>\n<p>这些block会分布在不同的机器上管理着，比如说一共有100台机器组成的集群，那么每台机器上放80个左右的block就ok了。</p>\n<p>但是问题又来了，那如果这个时候1台机器宕机了，不就导致80个block丢失了？</p>\n<p>也就是说上传上去的1TB的大文件，会丢失一小部分数据啊。没关系！HDFS都考虑好了！</p>\n<p>它会<strong>默认给每个block搞3个副本</strong>，一模一样的副本，分放在不同的机器上，如果一台机器宕机了，同一个block还有另外两个副本在其他机器上呢！</p>\n<p><strong>大伙儿看看下面这张图</strong>。每个block都在不同的机器上有3个副本，任何一台机器宕机都没事！还可以从其他的机器上拿到那个block。</p>\n<p>这下子，你往HDFS上传一个1TB的大文件，可以高枕无忧了吧！</p>\n<p><img src=\"https://user-gold-cdn.xitu.io/2018/11/13/1670dc07b1a880a6?imageView2/0/w/1280/h/960/ignore-error/1\" alt><br><a href></a></p>\n<p><a href></a></p>\n<p>OK，上面就是大白话加上一系列手绘图，给大家先聊聊小白都能听懂的Hadoop的基本架构原理</p>\n<p>接下来会给大家聊聊HDFS，这个作为世界上最优秀的分布式存储系统，承载高并发请求、高性能文件上传的一些核心机制以及原理。</p>\n<p><strong>《大规模集群下Hadoop如何承载每秒上千次的高并发访问》，</strong>敬请期待</p>\n<p><strong>《【冰山下的秘密】Hadoop如何将TB级大文件的上传性能提升上百倍？》</strong>，敬请期待</p>\n<p><strong>如有收获，请帮忙转发，您的鼓励是作者最大的动力，谢谢！</strong></p>\n<p><strong>一大波微服务、分布式、高并发、高可用的**</strong>原创系列<strong>**文章正在路上,</strong></p>\n<hr>\n<p><strong>**欢迎扫描下方二维码</strong>，持续关注：**\n<img src=\"https://user-gold-cdn.xitu.io/2018/11/12/167088310d1d57b1?imageView2/0/w/1280/h/960/ignore-error/1\" alt></p>\n<p><strong>石杉的架构笔记（id:shishan100）</strong></p>\n<p><strong>十余年BAT架构经验倾囊相授</strong></p>\n","categories":[],"tags":[{"name":"架构","slug":"架构","count":4,"path":"api/tags/架构.json"},{"name":"HDFS","slug":"HDFS","count":1,"path":"api/tags/HDFS.json"},{"name":"Hadoop","slug":"Hadoop","count":1,"path":"api/tags/Hadoop.json"},{"name":"MySQL","slug":"MySQL","count":2,"path":"api/tags/MySQL.json"}]}